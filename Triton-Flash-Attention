{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9983510,"sourceType":"datasetVersion","datasetId":6143538}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.4.0\n!pip install triton==3.0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:23:07.892368Z","iopub.execute_input":"2024-11-23T11:23:07.892748Z","iopub.status.idle":"2024-11-23T11:23:31.699477Z","shell.execute_reply.started":"2024-11-23T11:23:07.892720Z","shell.execute_reply":"2024-11-23T11:23:31.698205Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch==2.4.0 in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.4.0) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.4.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.4.0) (1.3.0)\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==3.0.0) (3.15.1)\nDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\nSuccessfully installed triton-3.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\n\nimport triton\nimport triton.language as tl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:42.647211Z","iopub.execute_input":"2024-11-23T11:14:42.648159Z","iopub.status.idle":"2024-11-23T11:14:46.573510Z","shell.execute_reply.started":"2024-11-23T11:14:42.648110Z","shell.execute_reply":"2024-11-23T11:14:46.572801Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"@triton.jit\ndef _attn_fwd_inner(\n    O_block,\n    l_i,\n    m_i,\n    Q_block,\n    K_block_ptr,\n    V_block_ptr,\n    block_index_q,\n    softmax_scale,\n    BLOCK_SIZE_Q: tl.constexpr,\n    BLOCK_SIZE_KV: tl.constexpr,\n    STAGE: tl.constexpr,\n    offs_q: tl.constexpr,\n    offs_kv: tl.constexpr,\n    SEQ_LEN: tl.constexpr,\n):\n    # range of values handled by this stage\n    if STAGE == 1:\n        # From 0 to the left of the diagonal\n        lo, hi = 0, block_index_q * BLOCK_SIZE_Q\n    elif STAGE == 2:\n        # Used only for the block in which there is transition between non-masked and masked keys\n        lo, hi = block_index_q * BLOCK_SIZE_Q, (block_index_q + 1) * BLOCK_SIZE_Q\n        lo = tl.multiple_of(lo, BLOCK_SIZE_Q)\n    else:\n        # Only used for non-causal attention\n        lo, hi = 0, SEQ_LEN\n\n    K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n\n    # loop over k, v and update accumulator\n    for start_kv in range(lo, hi, BLOCK_SIZE_KV):\n        # Just let the compiler know that start_n is a multiple of BLOCK_N, so the compiler can do optimizations\n        start_kv = tl.multiple_of(start_kv, BLOCK_SIZE_KV)\n\n        # -- compute qk ----\n        K_block = tl.load(K_block_ptr)\n        QK_block = tl.dot(Q_block, K_block)\n\n        if STAGE == 2:\n            mask = offs_q[:, None] >= (start_kv + offs_kv[None, :])\n            QK_block = QK_block * softmax_scale + tl.where(mask, 0, -1.0e6)\n            m_ij = tl.maximum(m_i, tl.max(QK_block, 1))\n            QK_block -= m_ij[:, None]\n        else:\n            # Compute the maximum value of qk or keep the old max value\n            m_ij = tl.maximum(m_i, tl.max(QK_block, 1) * softmax_scale)\n            QK_block = QK_block * softmax_scale - m_ij[:, None]\n\n        # Compute the exponential of each dot product, so now we are computing exp(qk_ij - m_ij)\n        P_block = tl.math.exp(QK_block)\n        # Compute the sum by rows of the attention scores\n        l_ij = tl.sum(P_block, 1)\n\n        # This is the correction factor for the previous l_i\n        alpha = tl.math.exp(m_i - m_ij)\n        # Apply the correction factor to the previous l_i and add the new l_ij\n        l_i = l_i * alpha + l_ij\n\n        V_block = tl.load(V_block_ptr)\n        P_block = P_block.to(tl.float16)\n        # This computes the following: O_new = P x V + O_old * alpha\n        O_block = O_block * alpha[:, None]\n        O_block = tl.dot(P_block, V_block, O_block)\n\n        m_i = m_ij\n\n        # Move to the next block of K and V\n        V_block_ptr = tl.advance(V_block_ptr, (BLOCK_SIZE_KV, 0))\n        K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_SIZE_KV))\n        \n    return O_block, l_i, m_i\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:46.575330Z","iopub.execute_input":"2024-11-23T11:14:46.575771Z","iopub.status.idle":"2024-11-23T11:14:46.588835Z","shell.execute_reply.started":"2024-11-23T11:14:46.575731Z","shell.execute_reply":"2024-11-23T11:14:46.588048Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"@triton.autotune(\n    configs=[\n        triton.Config(\n            {\"BLOCK_SIZE_Q\": BLOCK_SIZE_Q, \"BLOCK_SIZE_KV\": BLOCK_SIZE_KV},\n            num_stages=num_stages,\n            num_warps=num_warps,\n        )\n        for BLOCK_SIZE_Q in [64, 128]\n        for BLOCK_SIZE_KV in [32, 64]\n        for num_stages in [3, 4, 7]\n        for num_warps in [2, 4]\n    ],\n    key=[\"SEQ_LEN\", \"HEAD_DIM\"],\n)\n@triton.jit\ndef _attn_fwd(\n    Q,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n    K,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n    V,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n    softmax_scale,\n    M,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN\n    O,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n    stride_Q_batch,\n    stride_Q_head,\n    stride_Q_seq,\n    stride_Q_dim,\n    stride_K_batch,\n    stride_K_head,\n    stride_K_seq,\n    stride_K_dim,\n    stride_V_batch,\n    stride_V_head,\n    stride_V_seq,\n    stride_V_dim,\n    stride_O_batch,\n    stride_O_head,\n    stride_O_seq,\n    stride_O_dim,\n    BATCH_SIZE,\n    NUM_HEADS: tl.constexpr,\n    SEQ_LEN: tl.constexpr,\n    HEAD_DIM: tl.constexpr,\n    BLOCK_SIZE_Q: tl.constexpr,\n    BLOCK_SIZE_KV: tl.constexpr,\n    STAGE: tl.constexpr,\n):\n    tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n\n    # This indicate which block in the sequence length to process\n    block_index_q = tl.program_id(0)\n\n    # This indicates which head and batch to process. Each program is associated with a single head of a single batch\n    index_batch_head = tl.program_id(1)\n    # This indicate which batch this program is associated with (each batch has NUM_HEADS heads)\n    index_batch = index_batch_head // NUM_HEADS\n    # This indicate the position of the head in the batch\n    index_head = index_batch_head % NUM_HEADS\n\n    # This allows to get the (N_CTX, HEAD_DIM) block in the Q, K, V by selecting indexing it by batch and head\n    qvk_offset = (\n        index_batch.to(tl.int64) * stride_Q_batch\n        + index_head.to(tl.int64) * stride_Q_head\n    )\n\n    Q_block_ptr = tl.make_block_ptr(\n        base=Q + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_Q_seq, stride_Q_dim),\n        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n        order=(1, 0),\n    )\n\n    V_block_ptr = tl.make_block_ptr(\n        base=V + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_V_seq, stride_V_dim),\n        offsets=(0, 0),\n        block_shape=(BLOCK_SIZE_KV, HEAD_DIM),\n        order=(1, 0),\n    )\n\n    K_block_ptr = tl.make_block_ptr(\n        base=K + qvk_offset,\n        shape=(HEAD_DIM, SEQ_LEN),\n        strides=(\n            stride_K_dim,\n            stride_K_seq,\n        ),  # We invert the strides w.r.t Q, so we transpose the matrix\n        offsets=(0, 0),\n        block_shape=(HEAD_DIM, BLOCK_SIZE_KV),\n        order=(0, 1),\n    )\n\n    O_block_ptr = tl.make_block_ptr(\n        base=O + qvk_offset,\n        shape=(SEQ_LEN, HEAD_DIM),\n        strides=(stride_O_seq, stride_O_dim),\n        offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n        order=(1, 0),\n    )\n\n    # offs_q: the offsets for the tokens in the Q to process\n    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n    # offs_kv: the offsets for the tokens in the K and V sequence to process\n    offs_kv = tl.arange(0, BLOCK_SIZE_KV)\n\n    # m_i: the running maximum. We have one for each query\n    m_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) - float(\"inf\")\n    # l_i: the running sum. We have one for each query (as we sum the attention scores by rows)\n    l_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) + 1.0\n    # acc: the accumulator for the output, which is a group of rows of the O matrix\n    O_block = tl.zeros([BLOCK_SIZE_Q, HEAD_DIM], dtype=tl.float32)\n\n    # load the blocks of Q: it will stay in SRAM throughout\n    Q_block = tl.load(Q_block_ptr)\n\n    # Stage: 3 if causal, else 1\n\n    if STAGE == 1 or STAGE == 3:\n        # This step runs for non-causal attention or for the blocks to the left of the diagonal in the causal attention\n        O_block, l_i, m_i = _attn_fwd_inner(\n            O_block,\n            l_i,\n            m_i,\n            Q_block,\n            K_block_ptr,\n            V_block_ptr,\n            block_index_q,\n            softmax_scale,\n            BLOCK_SIZE_Q,\n            BLOCK_SIZE_KV,\n            4 - STAGE,\n            offs_q,\n            offs_kv,\n            SEQ_LEN,\n        )\n\n    if STAGE == 3:\n        # This step runs for the blocks to the right of the diagonal in the causal attention\n        O_block, l_i, m_i = _attn_fwd_inner(\n            O_block,\n            l_i,\n            m_i,\n            Q_block,\n            K_block_ptr,\n            V_block_ptr,\n            block_index_q,\n            softmax_scale,\n            BLOCK_SIZE_Q,\n            BLOCK_SIZE_KV,\n            2,\n            offs_q,\n            offs_kv,\n            SEQ_LEN,\n        )\n    # epilogue\n    m_i += tl.math.log(\n        l_i\n    )  # This is needed to compute the logsumexp for the backwards pass\n    O_block = O_block / l_i[:, None]\n    m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n    tl.store(m_ptrs, m_i)\n    tl.store(O_block_ptr, O_block.to(O.type.element_ty))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:46.589956Z","iopub.execute_input":"2024-11-23T11:14:46.590365Z","iopub.status.idle":"2024-11-23T11:14:48.482810Z","shell.execute_reply.started":"2024-11-23T11:14:46.590320Z","shell.execute_reply":"2024-11-23T11:14:48.481836Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"@triton.jit\ndef _attn_bwd_preprocess(\n    O,\n    dO,\n    D,\n    SEQ_LEN,\n    BLOCK_SIZE_Q: tl.constexpr,\n    HEAD_DIM: tl.constexpr,\n):\n    block_index_q = tl.program_id(0)\n    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n    index_batch_head = tl.program_id(1)\n    offs_dim = tl.arange(0, HEAD_DIM)\n    \n    # Load a single block of BLOCK_SIZE_Q rows of O\n    O_block = tl.load(\n        O\n        + index_batch_head * HEAD_DIM * SEQ_LEN\n        + offs_q[:, None] * HEAD_DIM\n        + offs_dim[None, :]\n    )\n    \n    # Load a single block of BLOCK_SIZE_Q rows of dO\n    dO_block = tl.load(\n        dO\n        + index_batch_head * HEAD_DIM * SEQ_LEN\n        + offs_q[:, None] * HEAD_DIM\n        + offs_dim[None, :]\n    ).to(tl.float32)\n    \n    # Compute the D block\n    D_block = tl.sum(dO_block * O_block, axis=1)  # Shape: (BLOCK_SIZE_Q,)\n    # Store the D block\n    D_block_ptrs = D + index_batch_head * SEQ_LEN + offs_q\n    tl.store(D_block_ptrs, D_block)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:48.484646Z","iopub.execute_input":"2024-11-23T11:14:48.484992Z","iopub.status.idle":"2024-11-23T11:14:48.505505Z","shell.execute_reply.started":"2024-11-23T11:14:48.484964Z","shell.execute_reply":"2024-11-23T11:14:48.501287Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"@triton.jit\ndef _attn_bwd_dk_dv(\n    Q,\n    K,\n    V,\n    softmax_scale,\n    dO,\n    dQ,\n    dK,\n    dV,\n    M,\n    D,\n    stride_batch,\n    stride_head,\n    stride_seq,\n    stride_dim,\n    NUM_HEADS,\n    SEQ_LEN,\n    BLOCK_Q: tl.constexpr,\n    BLOCK_KV: tl.constexpr,\n    HEAD_DIM: tl.constexpr,\n    STAGE: tl.constexpr,\n):\n    index_batch_head = tl.program_id(2)\n    index_batch = index_batch_head // NUM_HEADS\n    index_head = index_batch_head % NUM_HEADS\n    offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n        tl.int64\n    )\n    # This is the offset that allows us to select the right sequence given the batch and head.\n    offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n\n    # Make sure the pointers are in the right place w.r.t batch and head\n    # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n    Q += offset_batch_head\n    K += offset_batch_head\n    V += offset_batch_head\n    dO += offset_batch_head\n    dQ += offset_batch_head\n    dK += offset_batch_head\n    dV += offset_batch_head\n\n    # Make sure the pointers are in the right place w.r.t batch, head and sequence\n    M += offset_batch_head_seq\n    D += offset_batch_head_seq\n\n    # load scales\n    offs_dim = tl.arange(0, HEAD_DIM)\n\n    index_block_kv = tl.program_id(0)\n    start_kv = index_block_kv * BLOCK_KV\n\n    offs_kv = start_kv + tl.arange(0, BLOCK_KV)\n\n    dV_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n    dK_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n\n    # load K and V: they stay in SRAM throughout the inner loop.\n    K_block = tl.load(\n        K + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n    V_block = tl.load(\n        V + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n\n    offs_q = tl.arange(0, BLOCK_Q)\n\n    # We access the Q as a transposed array, so that's why we treat offs_q as a column vector ans offs_dim as a row vector\n    # This is equivalent to doing:\n    # q_ptrs = Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    # qT_ptrs = tl.trans(q_ptrs)\n    # We point to the first BLOCK_Q rows of Q for both the qT and dO pointers, inside the for loop we will move forward by BLOCK_Q rows at each iteration.\n    qT_ptrs = Q + offs_q[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n    dO_ptrs = dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n\n    # Iterates over the sequence dimension of the query\n    curr_q = 0\n    num_steps = SEQ_LEN // BLOCK_Q\n    for blk_idx in range(num_steps):\n        # Load a block of Q\n        qT_block = tl.load(qT_ptrs)\n        # Load the logsumexp values for the queries in the current block\n        offs_q = curr_q + tl.arange(0, BLOCK_Q)\n        m = tl.load(M + offs_q)\n\n        # This gives us (QK^T)^T = (K^T)^T(Q^T) = K(Q^T) = P^T\n        QK_T_block = softmax_scale * tl.dot(K_block, qT_block)\n        # We apply the softmax by using the logsumexp trick\n        P_T_block = tl.math.exp(QK_T_block - m[None, :])\n\n        if STAGE == 3:\n            # Autoregressive masking.\n            # mask is True for all values that DO NOT NEED TO BE MASKED\n            mask_block = (\n                offs_q[None, :] >= offs_kv[:, None]\n            )  # Shape: (BLOCK_KV1, BLOCK_Q1)\n            # Replace all the masked values with 0.\n            # In this case we do not need to mask with -Inf before applying the softmax since we already computed the normalization factors (stored in \"m\")\n            P_T_block = tl.where(mask_block, P_T_block, 0.0)\n\n        dO_block = tl.load(dO_ptrs)\n        # According to the formula: dV_new = dV_old + P^T x dO, where x is the matrix multiplication\n        dV_block += tl.dot(P_T_block.to(tl.float16), dO_block)\n\n        # Delta = rowsum(O * dO) where * is the element-wise product\n        Di = tl.load(D + offs_q)\n\n        # dP = dO x V^T, so dP^T = V x dO^T\n        # Where x is the matrix multiplication\n        dpT_block = tl.dot(V_block, tl.trans(dO_block)).to(tl.float32)\n\n        # We know that dS = P * (dP - Delta), so dS^T = P^T * (dP^T - Delta^T)\n\n        dS_T_block = P_T_block * (dpT_block - Di[None, :])\n        dS_T_block = dS_T_block.to(tl.float16)\n\n        # According to the formula on the paper: dK_new = dK_old + dS^T x Q\n        dK_block += softmax_scale * tl.dot(dS_T_block, tl.trans(qT_block))\n        # Increment pointers.\n        curr_q += BLOCK_Q\n        qT_ptrs += BLOCK_Q * stride_seq\n        dO_ptrs += BLOCK_Q * stride_seq\n\n    # Write back dV.\n    dV_block_ptrs = dV + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    tl.store(dV_block_ptrs, dV_block)\n\n    # Write back dK.\n    dK_block_ptrs = dK + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    tl.store(dK_block_ptrs, dK_block)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:48.506414Z","iopub.execute_input":"2024-11-23T11:14:48.506705Z","iopub.status.idle":"2024-11-23T11:14:48.534703Z","shell.execute_reply.started":"2024-11-23T11:14:48.506672Z","shell.execute_reply":"2024-11-23T11:14:48.533824Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"@triton.jit\ndef _attn_bwd_dk_dv(\n    Q,\n    K,\n    V,\n    softmax_scale,\n    dO,\n    dQ,\n    dK,\n    dV,\n    M,\n    D,\n    stride_batch,\n    stride_head,\n    stride_seq,\n    stride_dim,\n    NUM_HEADS,\n    SEQ_LEN,\n    BLOCK_Q: tl.constexpr,\n    BLOCK_KV: tl.constexpr,\n    HEAD_DIM: tl.constexpr,\n    STAGE: tl.constexpr,\n):\n    index_batch_head = tl.program_id(2)\n    index_batch = index_batch_head // NUM_HEADS\n    index_head = index_batch_head % NUM_HEADS\n    offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n        tl.int64\n    )\n    # This is the offset that allows us to select the right sequence given the batch and head.\n    offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n\n    # Make sure the pointers are in the right place w.r.t batch and head\n    # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n    Q += offset_batch_head\n    K += offset_batch_head\n    V += offset_batch_head\n    dO += offset_batch_head\n    dQ += offset_batch_head\n    dK += offset_batch_head\n    dV += offset_batch_head\n\n    # Make sure the pointers are in the right place w.r.t batch, head and sequence\n    M += offset_batch_head_seq\n    D += offset_batch_head_seq\n\n    # load scales\n    offs_dim = tl.arange(0, HEAD_DIM)\n\n    index_block_kv = tl.program_id(0)\n    start_kv = index_block_kv * BLOCK_KV\n\n    offs_kv = start_kv + tl.arange(0, BLOCK_KV)\n\n    dV_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n    dK_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n\n    # load K and V: they stay in SRAM throughout the inner loop.\n    K_block = tl.load(\n        K + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n    V_block = tl.load(\n        V + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    )  # Shape: (BLOCK_KV1, HEAD_DIM)\n\n    offs_q = tl.arange(0, BLOCK_Q)\n\n    # We access the Q as a transposed array, so that's why we treat offs_q as a column vector ans offs_dim as a row vector\n    # This is equivalent to doing:\n    # q_ptrs = Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    # qT_ptrs = tl.trans(q_ptrs)\n    # We point to the first BLOCK_Q rows of Q for both the qT and dO pointers, inside the for loop we will move forward by BLOCK_Q rows at each iteration.\n    qT_ptrs = Q + offs_q[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n    dO_ptrs = dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n\n    # Iterates over the sequence dimension of the query\n    curr_q = 0\n    num_steps = SEQ_LEN // BLOCK_Q\n    for blk_idx in range(num_steps):\n        # Load a block of Q\n        qT_block = tl.load(qT_ptrs)\n        # Load the logsumexp values for the queries in the current block\n        offs_q = curr_q + tl.arange(0, BLOCK_Q)\n        m = tl.load(M + offs_q)\n\n        # This gives us (QK^T)^T = (K^T)^T(Q^T) = K(Q^T) = P^T\n        QK_T_block = softmax_scale * tl.dot(K_block, qT_block)\n        # We apply the softmax by using the logsumexp trick\n        P_T_block = tl.math.exp(QK_T_block - m[None, :])\n\n        if STAGE == 3:\n            # Autoregressive masking.\n            # mask is True for all values that DO NOT NEED TO BE MASKED\n            mask_block = (\n                offs_q[None, :] >= offs_kv[:, None]\n            )  # Shape: (BLOCK_KV1, BLOCK_Q1)\n            # Replace all the masked values with 0.\n            # In this case we do not need to mask with -Inf before applying the softmax since we already computed the normalization factors (stored in \"m\")\n            P_T_block = tl.where(mask_block, P_T_block, 0.0)\n\n        dO_block = tl.load(dO_ptrs)\n        # According to the formula: dV_new = dV_old + P^T x dO, where x is the matrix multiplication\n        dV_block += tl.dot(P_T_block.to(tl.float16), dO_block)\n\n        # Delta = rowsum(O * dO) where * is the element-wise product\n        Di = tl.load(D + offs_q)\n\n        # dP = dO x V^T, so dP^T = V x dO^T\n        # Where x is the matrix multiplication\n        dpT_block = tl.dot(V_block, tl.trans(dO_block)).to(tl.float32)\n\n        # We know that dS = P * (dP - Delta), so dS^T = P^T * (dP^T - Delta^T)\n\n        dS_T_block = P_T_block * (dpT_block - Di[None, :])\n        dS_T_block = dS_T_block.to(tl.float16)\n\n        # According to the formula on the paper: dK_new = dK_old + dS^T x Q\n        dK_block += softmax_scale * tl.dot(dS_T_block, tl.trans(qT_block))\n        # Increment pointers.\n        curr_q += BLOCK_Q\n        qT_ptrs += BLOCK_Q * stride_seq\n        dO_ptrs += BLOCK_Q * stride_seq\n\n    # Write back dV.\n    dV_block_ptrs = dV + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    tl.store(dV_block_ptrs, dV_block)\n\n    # Write back dK.\n    dK_block_ptrs = dK + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n    tl.store(dK_block_ptrs, dK_block)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:48.537262Z","iopub.execute_input":"2024-11-23T11:14:48.537621Z","iopub.status.idle":"2024-11-23T11:14:48.563796Z","shell.execute_reply.started":"2024-11-23T11:14:48.537594Z","shell.execute_reply":"2024-11-23T11:14:48.562963Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class TritonAttention(torch.autograd.Function):\n\n    @staticmethod\n    def forward(ctx, Q, K, V, causal, softmax_scale):\n        HEAD_DIM_Q, HEAD_DIM_K = Q.shape[-1], K.shape[-1]\n        HEAD_DIM_V = V.shape[-1]\n\n        BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n\n        assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_K == HEAD_DIM_V\n\n        O = torch.empty_like(Q)\n        stage = 3 if causal else 1\n\n        grid = lambda args: (\n            triton.cdiv(SEQ_LEN, args[\"BLOCK_SIZE_Q\"]),\n            BATCH_SIZE * NUM_HEADS,\n            1,\n        )\n\n        # M is the logsumexp for the backward pass, one for each query\n        M = torch.empty(\n            (BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32\n        )\n\n        _attn_fwd[grid](\n            Q=Q,\n            K=K,\n            V=V,\n            softmax_scale=softmax_scale,\n            M=M,\n            O=O,\n            stride_Q_batch=Q.stride(0),\n            stride_Q_head=Q.stride(1),\n            stride_Q_seq=Q.stride(2),\n            stride_Q_dim=Q.stride(3),\n            stride_K_batch=K.stride(0),\n            stride_K_head=K.stride(1),\n            stride_K_seq=K.stride(2),\n            stride_K_dim=K.stride(3),\n            stride_V_batch=V.stride(0),\n            stride_V_head=V.stride(1),\n            stride_V_seq=V.stride(2),\n            stride_V_dim=V.stride(3),\n            stride_O_batch=O.stride(0),\n            stride_O_head=O.stride(1),\n            stride_O_seq=O.stride(2),\n            stride_O_dim=O.stride(3),\n            BATCH_SIZE=Q.shape[0],\n            NUM_HEADS=Q.shape[1],\n            SEQ_LEN=Q.shape[2],\n            HEAD_DIM=HEAD_DIM_K,\n            STAGE=stage,\n        )\n\n        ctx.save_for_backward(Q, K, V, O, M)\n        ctx.grid = grid\n        ctx.softmax_scale = softmax_scale\n        ctx.HEAD_DIM = HEAD_DIM_K\n        ctx.causal = causal\n        return O\n\n    @staticmethod\n    def backward(ctx, dO):\n        Q, K, V, O, M = ctx.saved_tensors\n\n        assert dO.is_contiguous()\n        assert Q.stride() == K.stride() == V.stride() == O.stride() == dO.stride()\n        dQ = torch.empty_like(Q)\n        dK = torch.empty_like(K)\n        dV = torch.empty_like(V)\n\n        BATCH_SIZE, NUM_HEADS, SEQ_LEN = Q.shape[:3]\n        NUM_WARPS, NUM_STAGES = 4, 3\n        BLOCK_SIZE_MICRO, BLOCK_SIZE_MACRO = 32, 128\n\n        preprocess_grid = (SEQ_LEN // BLOCK_SIZE_MACRO, BATCH_SIZE * NUM_HEADS)\n        D = torch.empty_like(M)  # Shape: (BATCH_SIZE, NUM_HEADS, SEQ_LEN)\n\n        # Compute all the elements Di\n        _attn_bwd_preprocess[preprocess_grid](\n            O=O,\n            dO=dO,\n            D=D,\n            SEQ_LEN=SEQ_LEN,\n            BLOCK_SIZE_Q=BLOCK_SIZE_MACRO,\n            HEAD_DIM=ctx.HEAD_DIM,\n        )\n\n        grid = (SEQ_LEN // BLOCK_SIZE_MACRO, 1, BATCH_SIZE * NUM_HEADS)\n\n        stage = 3 if ctx.causal else 1\n\n        # Fix KV and iterate through all the Q blocks\n        _attn_bwd_dk_dv[grid](\n            Q=Q,\n            K=K,\n            V=V,\n            softmax_scale=ctx.softmax_scale,\n            dO=dO,\n            dQ=dQ,\n            dK=dK,\n            dV=dV,\n            M=M,\n            D=D,\n            stride_batch=Q.stride(0),\n            stride_head=Q.stride(1),\n            stride_seq=Q.stride(2),\n            stride_dim=Q.stride(3),\n            NUM_HEADS=NUM_HEADS,\n            SEQ_LEN=SEQ_LEN,\n            BLOCK_Q=BLOCK_SIZE_MICRO,\n            BLOCK_KV=BLOCK_SIZE_MACRO,\n            HEAD_DIM=ctx.HEAD_DIM,\n            STAGE=stage,\n            num_warps=NUM_WARPS,\n            num_stages=NUM_STAGES,\n        )\n\n        # Fix Q and iterate through all the KV block\n        _attn_bwd_dq[grid](\n            Q=Q,\n            K=K,\n            V=V,\n            softmax_scale=ctx.softmax_scale,\n            dO=dO,\n            dQ=dQ,\n            dK=dK,\n            dV=dV,\n            M=M,\n            D=D,\n            stride_batch=Q.stride(0),\n            stride_head=Q.stride(1),\n            stride_seq=Q.stride(2),\n            stride_dim=Q.stride(3),\n            NUM_HEADS=NUM_HEADS,\n            SEQ_LEN=SEQ_LEN,\n            BLOCK_Q=BLOCK_SIZE_MACRO,\n            BLOCK_KV=BLOCK_SIZE_MICRO,\n            HEAD_DIM=ctx.HEAD_DIM,\n            STAGE=stage,\n            num_warps=NUM_WARPS,\n            num_stages=NUM_STAGES,\n        )\n\n        return dQ, dK, dV, None, None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:14:48.564864Z","iopub.execute_input":"2024-11-23T11:14:48.565162Z","iopub.status.idle":"2024-11-23T11:14:48.587701Z","shell.execute_reply.started":"2024-11-23T11:14:48.565134Z","shell.execute_reply":"2024-11-23T11:14:48.586865Z"},"_kg_hide-input":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, causal, dtype=torch.float16):\n    Q = (\n        torch.empty(\n            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n        )\n        .normal_(mean=0.0, std=0.5)\n        .requires_grad_()\n    )\n\n    K = (\n        torch.empty(\n            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n        )\n        .normal_(mean=0.0, std=0.5)\n        .requires_grad_()\n    )\n\n    V = (\n        torch.empty(\n            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n        )\n        .normal_(mean=0.0, std=0.5)\n        .requires_grad_()\n    )\n\n    softmax_scale = 1 / (HEAD_DIM ** 0.5)\n    dO = torch.randn_like(Q)\n\n    # refernce implementation\n    MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=\"cuda\"))\n    P = (Q @ K.transpose(2, 3)) * softmax_scale\n    if causal:\n        P[:, :, MASK==0] = float(\"-inf\")\n    P = torch.softmax(P.float(), dim=-1).half()\n    ref_O = P @ V\n    ref_O.backward(dO)\n    ref_dV, V.grad = V.grad.clone(), None\n    ref_dK, K.grad = K.grad.clone(), None\n    ref_dQ, Q.grad = Q.grad.clone(), None\n    \n    # triton implementation\n    tri_out = TritonAttention.apply(Q, K, V, causal, softmax_scale).half()\n    tri_out.backward(dO)\n    tri_dV, V.grad = V.grad.clone(), None\n    tri_dK, K.grad = K.grad.clone(), None\n    tri_dQ, Q.grad = Q.grad.clone(), None\n\n    # compare\n    rtol = 0.0\n    atol = 1e-2\n    assert torch.allclose(ref_O, tri_out, atol=atol, rtol=rtol)\n    assert torch.allclose(ref_dK, tri_dK, atol=atol, rtol=rtol)\n    assert torch.allclose(ref_dV, tri_dV, atol=atol, rtol=rtol)\n    assert torch.allclose(ref_dQ, tri_dQ, atol=atol, rtol=rtol)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:15:39.044884Z","iopub.execute_input":"2024-11-23T11:15:39.045221Z","iopub.status.idle":"2024-11-23T11:15:39.055306Z","shell.execute_reply.started":"2024-11-23T11:15:39.045190Z","shell.execute_reply":"2024-11-23T11:15:39.054311Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_op(BATCH_SIZE=2, NUM_HEADS=4, SEQ_LEN=1024, HEAD_DIM=64, causal=True)\n    test_op(BATCH_SIZE=2, NUM_HEADS=4, SEQ_LEN=1024, HEAD_DIM=64, causal=False)\n    print(\"PASSED\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T11:34:50.101715Z","iopub.execute_input":"2024-11-23T11:34:50.102127Z","iopub.status.idle":"2024-11-23T11:35:34.117326Z","shell.execute_reply.started":"2024-11-23T11:34:50.102093Z","shell.execute_reply":"2024-11-23T11:35:34.116337Z"}},"outputs":[{"name":"stdout","text":"PASSED\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}